{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "markov_rework.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO51IVg+4xTdIND7e9CW0cr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokymok/notebooks/blob/main/markov_rework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7K--7Qezi_C",
        "outputId": "153e0555-8028-44bc-f79c-9a0eb3e6b29e"
      },
      "source": [
        "!pip install discord"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting discord\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/76/75382e581c7932c177568e985a6967a305b1788f51936e819010e5538ef4/discord-1.0.1-py3-none-any.whl\n",
            "Collecting discord.py>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/b8/431808c895bb3a5ae24cfafc990c5fde0c4bbe07433cce29cd1f72bfb8d1/discord.py-1.7.2-py3-none-any.whl (786kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 5.1MB/s \n",
            "\u001b[?25hCollecting aiohttp<3.8.0,>=3.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<3.8.0,>=3.6.0->discord.py>=1.0.1->discord) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<3.8.0,>=3.6.0->discord.py>=1.0.1->discord) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp<3.8.0,>=3.6.0->discord.py>=1.0.1->discord) (3.7.4.3)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 25.0MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.8.0,>=3.6.0->discord.py>=1.0.1->discord) (2.10)\n",
            "Installing collected packages: multidict, yarl, async-timeout, aiohttp, discord.py, discord\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 discord-1.0.1 discord.py-1.7.2 multidict-5.1.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVgc3zzYRtv1",
        "outputId": "66853b45-7889-4b99-c0f7-52be4e1f0788"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "text_path = \"/content/model.txt\"\n",
        "def load_text(filename):\n",
        "    with open(filename,encoding='utf8') as f:\n",
        "        return f.read().lower()\n",
        "    \n",
        "text = load_text(text_path)\n",
        "print('Loaded the dataset.')\n",
        "\n",
        "def generateTable(data,k=5):\n",
        "    \n",
        "    T = {}\n",
        "    for i in range(len(data)-k):\n",
        "        X = data[i:i+k]\n",
        "        Y = data[i+k]\n",
        "        #print(\"X  %s and Y %s  \"%(X,Y))\n",
        "        \n",
        "        if T.get(X) is None:\n",
        "            T[X] = {}\n",
        "            T[X][Y] = 1\n",
        "        else:\n",
        "            if T[X].get(Y) is None:\n",
        "                T[X][Y] = 1\n",
        "            else:\n",
        "                T[X][Y] += 1\n",
        "    \n",
        "    return T\n",
        "\n",
        "T = generateTable(\"hello hello helli\")\n",
        "print(T)\n",
        "\n",
        "def convertFreqIntoProb(T):     \n",
        "    for kx in T.keys():\n",
        "        s = float(sum(T[kx].values()))\n",
        "        for k in T[kx].keys():\n",
        "            T[kx][k] = T[kx][k]/s\n",
        "                \n",
        "    return T\n",
        " \n",
        "T = convertFreqIntoProb(T)\n",
        "print(T)\n",
        "\n",
        "def MarkovChain(text,k=4):\n",
        "    T = generateTable(text,k)\n",
        "    T = convertFreqIntoProb(T)\n",
        "    return T\n",
        " \n",
        "model = MarkovChain(text)\n",
        "print('Model Created Successfully!')\n",
        "\n",
        "def sample_next(ctx,model,k):\n",
        " \n",
        "    ctx = ctx[-k:]\n",
        "    if model.get(ctx) is None:\n",
        "        return \" \"\n",
        "    possible_Chars = list(model[ctx].keys())\n",
        "    possible_values = list(model[ctx].values())\n",
        " \n",
        "    return np.random.choice(possible_Chars,p=possible_values)\n",
        " \n",
        "sample_next(\"commo\",model,4)\n",
        "\n",
        "def generateText(starting_sent,k=4,maxLen=1000):\n",
        "    \n",
        "    sentence = starting_sent\n",
        "    ctx = starting_sent[-k:]\n",
        "    \n",
        "    for ix in range(maxLen):\n",
        "        next_prediction = sample_next(ctx,model,k)\n",
        "        sentence += next_prediction\n",
        "        ctx = sentence[-k:]\n",
        "    return sentence\n",
        " \n",
        "print(\"Function Created Successfully!\")\n",
        " \n",
        "text = generateText(\"hello\",k=4,maxLen=200)\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the dataset.\n",
            "{'hello': {' ': 2}, 'ello ': {'h': 2}, 'llo h': {'e': 2}, 'lo he': {'l': 2}, 'o hel': {'l': 2}, ' hell': {'o': 1, 'i': 1}}\n",
            "{'hello': {' ': 1.0}, 'ello ': {'h': 1.0}, 'llo h': {'e': 1.0}, 'lo he': {'l': 1.0}, 'o hel': {'l': 1.0}, ' hell': {'o': 0.5, 'i': 0.5}}\n",
            "Model Created Successfully!\n",
            "Function Created Successfully!\n",
            "hello\n",
            "here in the blowerofthephall\n",
            "@everyone\n",
            "@everyone!\n",
            "today\n",
            "bunch. 0/10 she looks like so the hedgehog is so you nuts*\n",
            "*smack that shit birthday but explories well his back hurts twitch\n",
            "give you veryone\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmg7ZzlYTa2G"
      },
      "source": [
        "import pandas as pd\n",
        "dict_df = pd.DataFrame(columns = [‘lead’, ‘follow’, ‘freq’])\n",
        "dict_df['lead']=words\n",
        "follow = words[1:]\n",
        "follow.append('EndWord')\n",
        "\n",
        "dict_df['freq']= dict_df.groupby(by=['lead','follow'])['lead','follow'].transform('count').copy()\n",
        "\n",
        "dict_df = dict_df.drop_duplicates()\n",
        "pivot_df = dict_df.pivot(index = 'lead', columns= 'follow', values='freq')\n",
        "\n",
        "sum_words = pivot_df.sum(axis=1)\n",
        "pivot_df = pivot_df.apply(lambda x: x/sum_words)\n",
        "\n",
        "from numpy.random import choice\n",
        "def make_a_sentence(start):\n",
        "    word= start\n",
        "    sentence=[word]\n",
        "    while len(sentence) < 30:\n",
        "        next_word = choice(a = list(pivot_df.columns), p = (pivot_df.iloc[pivot_df.index ==word].fillna(0).values)[0])\n",
        "        if next_word == 'EndWord':\n",
        "                continue\n",
        "        elif next_word in end_words:\n",
        "            if len(sentence) > 2:    \n",
        "                sentence.append(next_word)\n",
        "                break\n",
        "            else :\n",
        "                continue\n",
        "        else :\n",
        "            sentence.append(next_word)\n",
        "        word=next_word\n",
        "    sentence = ' '.join(sentence)\n",
        "    return sentence\n",
        "sentence = make_a_sentence('Donald')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ31cYGuqLHE",
        "outputId": "f5d999c7-df2e-42aa-c1b0-0a21faac69a3"
      },
      "source": [
        "import random \n",
        "import re \n",
        "text_path = \"/content/model.txt\"\n",
        "def load_text(filename):\n",
        "    with open(filename,encoding='utf8') as f:\n",
        "        return f.read().lower()\n",
        "    \n",
        "text = load_text(text_path)\n",
        "tokenized_text = [\n",
        "    word\n",
        "    for word in re.split('\\W+', text)\n",
        "    if word != ''\n",
        "]\n",
        "words = []  \n",
        "for line in tokenized_text:  \n",
        "    line = line.replace('\\r', ' ').replace('\\n', ' ')\n",
        "    new_words = line.split(' ')\n",
        "    new_words = [word for word in new_words if word not in ['', ' ']]\n",
        "    words = words + new_words\n",
        "print('Corpus size: {0} words.'.format(len(words)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus size: 42803 words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx2gpoO8qWCf",
        "outputId": "fc9b60f2-5e89-4372-9641-6e66386693b0"
      },
      "source": [
        "chain = {}  \n",
        "n_words = len(words)  \n",
        "for i, key1 in enumerate(words):  \n",
        "    if n_words > i + 2:\n",
        "        key2 = words[i + 1]\n",
        "        word = words[i + 2]\n",
        "        if (key1, key2) not in chain:\n",
        "            chain[(key1, key2)] = [word]\n",
        "        else:\n",
        "            chain[(key1, key2)].append(word)\n",
        "print('Chain size: {0} distinct word pairs.'.format(len(chain)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chain size: 16787 distinct word pairs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxAVuBPjwRIE"
      },
      "source": [
        "def markov_message(chain, words):  \n",
        "    r = random.randint(0, len(words) - 1)\n",
        "    key = (words[r], words[r + 1])\n",
        "    message = key[0] + ' ' + key[1]\n",
        "\n",
        "    while len(message) < random.randint(5,250):\n",
        "        w = random.choice(chain[key])\n",
        "        message += ' ' + w\n",
        "        key = (key[1], w)\n",
        "    print(message + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt6NW5GZwZnq",
        "outputId": "6ec094b3-1983-423b-b7a3-4147ecf1cd24"
      },
      "source": [
        "markov_message(chain, words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check how could you have to say it goodbye goodbye exactly y all go wheres the one for ku\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-hK82nJwdF6",
        "outputId": "f549330a-938a-44c6-e922-9a070b453ba7"
      },
      "source": [
        "import random \n",
        "import re \n",
        "import discord\n",
        "from discord import Intents\n",
        "import asyncio\n",
        "from discord.ext import commands\n",
        "\n",
        "text_path = \"/content/model.txt\"\n",
        "\n",
        "def load_text(filename):\n",
        "    with open(filename,encoding='utf8') as f:\n",
        "        return f.read().lower()\n",
        "    \n",
        "text = load_text(text_path)\n",
        "tokenized_text = [\n",
        "    word\n",
        "    for word in re.split('\\W+', text)\n",
        "    if word != ''\n",
        "]\n",
        "words = []  \n",
        "for line in tokenized_text:  \n",
        "    line = line.replace('\\r', ' ').replace('\\n', ' ')\n",
        "    new_words = line.split(' ')\n",
        "    new_words = [word for word in new_words if word not in ['', ' ']]\n",
        "    words = words + new_words\n",
        "print('Corpus size: {0} words.'.format(len(words)))\n",
        "\n",
        "chain = {}  \n",
        "n_words = len(words)  \n",
        "for i, key1 in enumerate(words):  \n",
        "    if n_words > i + 2:\n",
        "        key2 = words[i + 1]\n",
        "        word = words[i + 2]\n",
        "        if (key1, key2) not in chain:\n",
        "            chain[(key1, key2)] = [word]\n",
        "        else:\n",
        "            chain[(key1, key2)].append(word)\n",
        "print('Chain size: {0} distinct word pairs.'.format(len(chain)))\n",
        "\n",
        "def markov_message(chain, words):  \n",
        "    r = random.randint(0, len(words) - 1)\n",
        "    key = (words[r], words[r + 1])\n",
        "    message = key[0] + ' ' + key[1]\n",
        "\n",
        "    while len(message) < random.randint(5,280):\n",
        "        w = random.choice(chain[key])\n",
        "        message += ' ' + w\n",
        "        key = (key[1], w)\n",
        "    print(message + '\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus size: 42803 words.\n",
            "Chain size: 16787 distinct word pairs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBNXhWviCAtW",
        "outputId": "d05926bc-3c67-468b-8a0e-89acacb514c4"
      },
      "source": [
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "like a margarita wanna feel his dna\n",
            "\n",
            "nmarkov nmarkov nmarkov nmarkov nmarkov nmarkov nmarkov nmarkov nmarkov\n",
            "\n",
            "bitch with the cabal on mars so let s start this\n",
            "\n",
            "me can you help me only seven inches long uwu please adopt me paws on your\n",
            "\n",
            "for not saying fuck now with that so just\n",
            "\n",
            "best ship is abram\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btxvOUMpCk0s",
        "outputId": "1b7acffc-980b-47ea-a2e0-c9c6f7b4d1cf"
      },
      "source": [
        "chain = {}  \n",
        "n_words = len(words)  \n",
        "for i, key1 in enumerate(words):  \n",
        "    if n_words > i + 3:\n",
        "        key2 = words[i + 1]\n",
        "        key3 = words[i + 2]\n",
        "        word = words[i + 3]\n",
        "        if (key1, key2, key3) not in chain:\n",
        "            chain[(key1, key2, key3)] = [word]\n",
        "        else:\n",
        "            chain[(key1, key2, key3)].append(word)\n",
        "print('Chain size: {0} distinct word phrases.'.format(len(chain)))\n",
        "\n",
        "def markov_message(chain, words):  \n",
        "    r = random.randint(0, len(words) - 1)\n",
        "    key = (words[r], words[r + 1], words[r + 2])\n",
        "    message = key[0] + ' ' + key[1]\n",
        "\n",
        "    while len(message) < random.randint(5,280):\n",
        "        w = random.choice(chain[key])\n",
        "        message += ' ' + w\n",
        "        key = (key[1], key[2], w)\n",
        "    print(message + '\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chain size: 22428 distinct word phrases.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbUojyXMEhnm",
        "outputId": "a7ceed74-c21c-439b-8658-40c9304f478b"
      },
      "source": [
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)\n",
        "markov_message(chain, words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grandfather put through i\n",
            "\n",
            "long ago fomented rebellion against the king\n",
            "\n",
            "and i give it unto you to possess it a land that floweth with milk\n",
            "\n",
            "to kill mockingbird the godfather\n",
            "\n",
            "and amg hellfire missiles on my body from now\n",
            "\n",
            "fuck on daughter water water water\n",
            "\n",
            "and start undress she sees my dick and sighs\n",
            "\n",
            "to die you can\n",
            "\n",
            "why they t done so in beijing s eyes hong kong is a uniquely\n",
            "\n",
            "ass motherfucker pissed on my fucking wife i ve come to\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piUMxjUrE23q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ef7c70-9e92-4f33-a178-6a75f8aab9c3"
      },
      "source": [
        "import random \n",
        "import re \n",
        "import discord\n",
        "import asyncio\n",
        "from discord.ext import commands\n",
        "from discord import Intents\n",
        "\n",
        "\n",
        "\n",
        "text_path = \"/content/model.txt\"\n",
        "intents = Intents.all()\n",
        "bot = commands.Bot(intents = intents, command_prefix = '!')\n",
        "token = ''\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "print(loop)\n",
        "\n",
        "words = []  \n",
        "chain = {}  \n",
        "autorate = 8\n",
        "ticker = 0\n",
        "\n",
        "\n",
        "\n",
        "@bot.event\n",
        "async def on_ready(self):\n",
        "    print('Logged on as' + self)\n",
        "    await bot.change_presence(\n",
        "        activity = discord.Activity(\n",
        "            type = discord.ActivityType.listening, \n",
        "            name = 'You'))\n",
        "\n",
        "\n",
        "def load_text(filename):\n",
        "    with open(filename,encoding='utf8') as f:\n",
        "        return f.read().lower()\n",
        "\n",
        "def markov_message(chain, words):  \n",
        "    r = random.randint(0, len(words) - 1)\n",
        "    key = (words[r], words[r + 1], words[r + 2])\n",
        "    message = key[0] + ' ' + key[1]\n",
        "\n",
        "    while len(message) < random.randint(5,280):\n",
        "        w = random.choice(chain[key])\n",
        "        message += ' ' + w\n",
        "        key = (key[1], key[2], w)\n",
        "    print(message + '\\n')\n",
        "\n",
        "\n",
        "@bot.listen(\"on_message\")\n",
        "async def train(ctx, self):\n",
        "    ctxtext = ctx.content\n",
        "    if ctx.author == self:\n",
        "        return\n",
        "\n",
        "    model_file = open(text_path, 'a')\n",
        "    model_file.write(ctxtext)\n",
        "    model_file.close()\n",
        "\n",
        "    ticker = (ticker + 1)\n",
        "    \n",
        "    text = load_text(text_path)\n",
        "    tokenized_text = [\n",
        "        word\n",
        "        for word in re.split('\\W+', text)\n",
        "        if word != '']\n",
        "\n",
        "    for line in tokenized_text:  \n",
        "        line = line.replace('\\r', ' ').replace('\\n', ' ')\n",
        "        new_words = line.split(' ')\n",
        "        new_words = [word for word in new_words if word not in ['', ' ']]\n",
        "        words = words + new_words\n",
        "    print('Corpus size: {0} words.'.format(len(words)))\n",
        "\n",
        "    n_words = len(words)  \n",
        "    for i, key1 in enumerate(words):  \n",
        "        if n_words > i + 3:\n",
        "            key2 = words[i + 1]\n",
        "            key3 = words[i + 2]\n",
        "            word = words[i + 3]\n",
        "            if (key1, key2, key3) not in chain:\n",
        "                chain[(key1, key2, key3)] = [word]\n",
        "        else:\n",
        "              chain[(key1, key2, key3)].append(word)\n",
        "    print('Chain size: {0} distinct word phrases.'.format(len(chain)))\n",
        "\n",
        "    if ticker >= autorate:\n",
        "        ticker = 0\n",
        "        await ctx.send(markov_message(chain, words))\n",
        "\n",
        "@bot.command(pass_context=True)\n",
        "async def join(ctx):\n",
        "    chan = ctx.author.voice.channel\n",
        "    await chan.connect()\n",
        "\n",
        "@bot.command(pass_context=True)\n",
        "async def leave(ctx):\n",
        "    await ctx.voice_client.disconnect()\n",
        "\n",
        "@bot.command(pass_context=True)\n",
        "async def autorate(ctx, a:int):\n",
        "    autorate = a\n",
        "    await ctx.send(\"Autorate has been set to:\" + a)\n",
        "\n",
        "if loop.is_running() == False:\n",
        "    bot.run(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_UnixSelectorEventLoop running=True closed=False debug=False>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRON2G9amu8D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}