{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pandas_loadingdata_LECTURE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokymok/notebooks/blob/main/pandas_loadingdata_lecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvNsvUNNlZbi"
      },
      "source": [
        "---\n",
        "# Lambda School Data Science - Intro to Pandas \n",
        "---\n",
        "# Lecture 05 - Loading Data \n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veCoTayWYvhi"
      },
      "source": [
        "### Begin by importing your tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwG232gHDwLT"
      },
      "source": [
        "# Let's begin by importing pandas\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c09PbwADn2D8"
      },
      "source": [
        "# help(pd.read_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRwAsUDmodPV"
      },
      "source": [
        "?pd.read_csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRH-6zIAX6D4"
      },
      "source": [
        "## Reading in Your Data\n",
        "Pandas has methods to read different types of data files and turn them into a DataFrame. In practice, you could be pulling data from different databases, different websites, your local computer, or a combination of all the above. For our purposes in the pre-course, we'll focus on the most common pandas method:  \n",
        "**`pandas.read_csv()`**\n",
        "\n",
        "CSV stands for \"comma separated values.\" If you've ever used Microsoft Excel or Google Sheets, for example, you've used CSV files. Keep this link to the documentation handy. Learning how to read documentation will become an invaluable asset in your journey.\n",
        "[Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdZek6VxJlVT"
      },
      "source": [
        "### Load a Dataset via its URL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-4aaacNyNl1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "48d63278-6cdd-4401-87fd-574dc2cab393"
      },
      "source": [
        "# We use the pandas method pandas.read_csv(\"filepath\") to create a DataFrame \n",
        "# and assign it to a variable:\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/axrd/datasets/master/sales_data.csv\")\n",
        "\n",
        "# Why do you think we assigned the new DataFrame to a variable? \n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Name</th>\n",
              "      <th>Region</th>\n",
              "      <th>Company</th>\n",
              "      <th>Date</th>\n",
              "      <th>Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Brenden Cote</td>\n",
              "      <td>Central African Republic</td>\n",
              "      <td>Metus Corp.</td>\n",
              "      <td>Feb 17, 2018</td>\n",
              "      <td>67044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Justina Reed</td>\n",
              "      <td>Namibia</td>\n",
              "      <td>Lobortis Ltd</td>\n",
              "      <td>Apr 27, 2017</td>\n",
              "      <td>89517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Daquan Vinson</td>\n",
              "      <td>Svalbard and Jan Mayen Islands</td>\n",
              "      <td>A Mi Consulting</td>\n",
              "      <td>Aug 14, 2016</td>\n",
              "      <td>62705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Connor Shelton</td>\n",
              "      <td>Niue</td>\n",
              "      <td>Parturient Consulting</td>\n",
              "      <td>Feb 13, 2017</td>\n",
              "      <td>12675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Drew Carlson</td>\n",
              "      <td>Mayotte</td>\n",
              "      <td>Interdum Associates</td>\n",
              "      <td>Sep 26, 2017</td>\n",
              "      <td>86670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0            Name  ...          Date  Sales\n",
              "0           0    Brenden Cote  ...  Feb 17, 2018  67044\n",
              "1           1    Justina Reed  ...  Apr 27, 2017  89517\n",
              "2           2   Daquan Vinson  ...  Aug 14, 2016  62705\n",
              "3           3  Connor Shelton  ...  Feb 13, 2017  12675\n",
              "4           4    Drew Carlson  ...  Sep 26, 2017  86670\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab-ObtnyJrOZ"
      },
      "source": [
        "### Load a Dataset from your local machine\n",
        "\n",
        "Take a look at the folder where this dataset can be found on GitHub: [sales_data.csv](https://github.com/axrd/datasets/blob/master/sales_data.csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwwE0RCcJjua"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jCLOpsjK4v7"
      },
      "source": [
        "df = pd.read_csv('sales_data.csv')\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X239QCLc1uI5"
      },
      "source": [
        "## Heads or Tails?\n",
        "The cell ran...but how do we know if we got our data?\n",
        "Pandas has a few methods that can help us verify:  \n",
        "\n",
        "`dataframe.head()`  \n",
        "\n",
        "Will show us the ***first*** 5 rows of our dataframe, we can pass an integer value into the parenthesis to see a specific number of rows.\n",
        "\n",
        "`dataframe.tail()`\n",
        "\n",
        "Will show us the ***last*** 5 rows of our dataframe, we can pass an integer value into the parenthesis to see a specific number of rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoGSRkP6zxQq"
      },
      "source": [
        "# Look at the first 5 rows:\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XaxmoADP9YD"
      },
      "source": [
        "# Look at the last 5 rows:\n",
        "\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkOuHb2958oi"
      },
      "source": [
        "Hmm...it looks like we may have two indexes. We'll fix that a little later. \n",
        "\n",
        "Right now, notice that df.head() and df.tail() return the first five rows and the last five rows of the DataFrame, respectively. But what if I wanted to see the first ten rows?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx7WMglQQBzD"
      },
      "source": [
        "df.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nALK3N9ZQZ5N"
      },
      "source": [
        "The head() method takes in a parameter that tells it how many rows to return (from the top). The tail() method has the same parameters, but from the bottom instead. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2lO_B2RR9zM"
      },
      "source": [
        "From our head() and tails() output we can see that we have people, regions, companies, dates, and sales numbers. Let's say we knew that this data was supposed to have 100 rows and 5 columns. How could we verify that we imported the data correctly?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9fKYbrPQB6M"
      },
      "source": [
        "# Pandas DataFrames have the same useful attribute as Numpy ndarrays: shape.\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT2jn1JTSuB6"
      },
      "source": [
        "We already knew this, but we've got one extra column (the duplicate index). Don't worry, this can happen! Fortunately, data frames have a method to drop columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEgLfS46TvMO"
      },
      "source": [
        "# Use the dataframe.columns attribute to get a series of the column names:\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCznVzcq_5bH"
      },
      "source": [
        "# If we just want a list of the column headers we can cast the index to a list\n",
        "list(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY9Rnxc_QB8-"
      },
      "source": [
        "# We need to drop the first column, but it's Unnamed so we need to use its index value.\n",
        "# Remember that index values begin at 0!\n",
        "\n",
        "df.columns[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QglBE_sGQCA6"
      },
      "source": [
        "# Using the dataframe.drop() method:\n",
        "\n",
        "# The the following two lines of code are equivalent\n",
        "df.drop(df.columns[0])\n",
        "# df.drop('Unnamed: 0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6HwmFdNULcL"
      },
      "source": [
        "### Axis? What's that all about?  \n",
        "### This:\n",
        "![atext](https://i.stack.imgur.com/dcoE3.jpg)  \n",
        "If you check the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html), you'll see that DataFrame.drop() has \"axis = 0\" as a default. We need to explicitly (remember the Zen of Python?) tell pandas to look for the column we want to drop from the column axis, which is column 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqPUmTFRUKjI"
      },
      "source": [
        "# Second time's the charm!\n",
        "\n",
        "df.drop(df.columns[0], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHj1X8i3WveJ"
      },
      "source": [
        "# We did it! Wait... Why is it still there? ðŸ¤”\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASCQt47eXDNb"
      },
      "source": [
        "### Not quite...\n",
        "### Pandas will almost always perform the operation and then return a copy of the changed DataFrame. But the original DataFrame is still the same. We need to override that! \n",
        "We can accomplish this a few different ways; the easiest is making the change _in place_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Zco0vPWzAJ"
      },
      "source": [
        "df.drop(df.columns[0], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF4F0dhmuK8o"
      },
      "source": [
        "# I suggest using this approach: \n",
        "df = df.drop(df.columns[0], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9EI4_reXirH"
      },
      "source": [
        "# Third time's the charm?\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR0Y4x49XyY4"
      },
      "source": [
        "## Renaming a Column\n",
        "On closer inspection, the column \"Region\" should really be called \"Country.\" Let's make that happen, _in place_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B04twRrdX_D2"
      },
      "source": [
        "df.rename(columns={'Region':'Country'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4KGpNxcYWY4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BqbpyNyzxqk"
      },
      "source": [
        "### Let's get started on your assignment!"
      ]
    }
  ]
}